{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-Bit Flip-Flop Working Memory Task\n",
    "\n",
    "This notebook demonstrates how to apply the RNN framework to a different task: the **3-bit flip-flop** working memory task.\n",
    "\n",
    "## Task Description\n",
    "\n",
    "The flip-flop task tests a network's ability to maintain state over time:\n",
    "- **3 input channels**: Binary pulses that command state toggles\n",
    "- **3 output channels**: Current state of each flip-flop (0 or 1)\n",
    "- **Rule**: An input pulse on channel *i* toggles flip-flop *i*\n",
    "- **Challenge**: Remember and maintain state with no continuous input\n",
    "\n",
    "This is a classic working memory benchmark from:\n",
    "- Sussillo & Barak (2013) - *Opening the Black Box*\n",
    "- Mante et al. (2013) - *Context-dependent computation*\n",
    "\n",
    "## What We'll Cover\n",
    "\n",
    "1. âœ… Load flip-flop dataset from `src.data.flipflop`\n",
    "2. ðŸ§  Train **CT-RNN** on working memory task\n",
    "3. âš–ï¸ Train **Balanced Rate Network** for comparison\n",
    "4. ðŸ“Š **PCA visualization** of hidden state dynamics\n",
    "5. ðŸŽ¯ **Fixed point analysis** of learned representations\n",
    "6. ðŸ“ˆ Training curves and test accuracy\n",
    "7. ðŸ” Compare architectures on working memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Google Colab setup\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Running in Google Colab - installing dependencies...\")\n",
    "    !pip install -q torch torchdiffeq matplotlib scipy tqdm\n",
    "    !git clone -q https://github.com/CNNC-Lab/RNNs-tutorial.git\n",
    "    %cd RNNs-tutorial\n",
    "    print(\"âœ“ Setup complete!\")\n",
    "\n",
    "from src import setup_environment, check_dependencies\n",
    "\n",
    "check_dependencies()\n",
    "device = setup_environment()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load Flip-Flop Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from src.data.flipflop import create_flipflop_dataloaders, plot_flipflop_trial\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader, val_loader, test_loader, info = create_flipflop_dataloaders(\n",
    "    train_trials=800,\n",
    "    val_trials=100,\n",
    "    test_trials=100,\n",
    "    n_bits=3,\n",
    "    seq_length=100,\n",
    "    pulse_prob=0.1,\n",
    "    batch_size=32,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"Dataset Info:\")\n",
    "for key, value in info.items():\n",
    "    print(f\"  {key}: {value}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Example Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get a batch of data\n",
    "sample_inputs, sample_targets = next(iter(train_loader))\n",
    "\n",
    "print(f\"Batch shapes:\")\n",
    "print(f\"  Inputs: {sample_inputs.shape}  # (batch, seq_length, n_bits)\")\n",
    "print(f\"  Targets: {sample_targets.shape}\")\n",
    "\n",
    "# Plot first trial\n",
    "fig = plot_flipflop_trial(\n",
    "    sample_inputs.numpy(),\n",
    "    sample_targets.numpy(),\n",
    "    trial_idx=0,\n",
    "    figsize=(14, 8)\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Œ Notice: Gray pulses toggle the state. Network must remember toggles with no continuous input!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Train Continuous-Time RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from src.models import ContinuousTimeRNN\n",
    "\n",
    "# Create CT-RNN\n",
    "ctrnn = ContinuousTimeRNN(\n",
    "    input_size=3,\n",
    "    hidden_size=64,\n",
    "    output_size=3,\n",
    "    tau=5.0,  # Longer time constant for working memory\n",
    "    activation='tanh',\n",
    "    solver='euler'\n",
    ").to(device)\n",
    "\n",
    "n_params = sum(p.numel() for p in ctrnn.parameters())\n",
    "print(f\"CT-RNN Parameters: {n_params:,}\")\n",
    "print(f\"Time constant Ï„: {ctrnn.cell.tau}\")\n",
    "\n",
    "# Test forward pass\n",
    "with torch.no_grad():\n",
    "    test_out = ctrnn(sample_inputs[:2].to(device))\n",
    "    print(f\"\\nForward pass: {sample_inputs[:2].shape} â†’ {test_out.shape}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from src.utils import train_model\n",
    "\n",
    "print(\"Training CT-RNN on flip-flop task...\\n\")\n",
    "\n",
    "history_ctrnn = train_model(\n",
    "    model=ctrnn,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    n_epochs=150,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-5,\n",
    "    patience=25,\n",
    "    device=device,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Save checkpoint\n",
    "torch.save(ctrnn.state_dict(), 'checkpoints/ctrnn_flipflop_best.pt')\n",
    "print(f\"\\nâœ“ CT-RNN trained! Best val loss: {min(history_ctrnn['val_loss']):.6f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Train Balanced Rate Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from src.models import BalancedRateNetwork\n",
    "\n",
    "# Create Balanced Rate Network\n",
    "balanced_rnn = BalancedRateNetwork(\n",
    "    input_size=3,\n",
    "    n_excitatory=96,\n",
    "    n_inhibitory=24,\n",
    "    output_size=3,\n",
    "    tau_e=5.0,  # Match CT-RNN time constant\n",
    "    tau_i=2.5,\n",
    "    activation='relu'\n",
    ").to(device)\n",
    "\n",
    "n_params_balanced = sum(p.numel() for p in balanced_rnn.parameters())\n",
    "print(f\"Balanced RNN Parameters: {n_params_balanced:,}\")\n",
    "print(f\"Architecture: {balanced_rnn.n_excitatory}E + {balanced_rnn.n_inhibitory}I neurons\")\n",
    "\n",
    "# Test forward pass\n",
    "with torch.no_grad():\n",
    "    test_out_bal = balanced_rnn(sample_inputs[:2].to(device))\n",
    "    print(f\"\\nForward pass: {sample_inputs[:2].shape} â†’ {test_out_bal.shape}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"Training Balanced Rate Network on flip-flop task...\\n\")\n",
    "\n",
    "history_balanced = train_model(\n",
    "    model=balanced_rnn,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    n_epochs=150,\n",
    "    lr=5e-4,\n",
    "    weight_decay=1e-5,\n",
    "    patience=25,\n",
    "    device=device,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Save checkpoint\n",
    "torch.save(balanced_rnn.state_dict(), 'checkpoints/balanced_flipflop_best.pt')\n",
    "print(f\"\\nâœ“ Balanced RNN trained! Best val loss: {min(history_balanced['val_loss']):.6f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Training Curves Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# CT-RNN\n",
    "axes[0].plot(history_ctrnn['train_loss'], label='Train Loss', linewidth=2, alpha=0.8)\n",
    "axes[0].plot(history_ctrnn['val_loss'], label='Val Loss', linewidth=2, alpha=0.8)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss (MSE)', fontsize=12)\n",
    "axes[0].set_title('CT-RNN Training', fontsize=13, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# Balanced RNN\n",
    "axes[1].plot(history_balanced['train_loss'], label='Train Loss', linewidth=2, alpha=0.8, color='orange')\n",
    "axes[1].plot(history_balanced['val_loss'], label='Val Loss', linewidth=2, alpha=0.8, color='red')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Loss (MSE)', fontsize=12)\n",
    "axes[1].set_title('Balanced Rate Network Training', fontsize=13, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from src.utils import evaluate\n",
    "from src.data.flipflop import compute_flipflop_accuracy\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Evaluate CT-RNN\n",
    "ctrnn.eval()\n",
    "test_loss_ctrnn, preds_ctrnn, targets_ctrnn = evaluate(ctrnn, test_loader, criterion, device)\n",
    "accuracy_ctrnn = compute_flipflop_accuracy(preds_ctrnn, targets_ctrnn)\n",
    "\n",
    "# Evaluate Balanced RNN\n",
    "balanced_rnn.eval()\n",
    "test_loss_balanced, preds_balanced, targets_balanced = evaluate(balanced_rnn, test_loader, criterion, device)\n",
    "accuracy_balanced = compute_flipflop_accuracy(preds_balanced, targets_balanced)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST SET PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nCT-RNN:\")\n",
    "print(f\"  MSE Loss: {test_loss_ctrnn:.6f}\")\n",
    "print(f\"  Bit Accuracy: {accuracy_ctrnn*100:.2f}%\")\n",
    "print(f\"\\nBalanced Rate Network:\")\n",
    "print(f\"  MSE Loss: {test_loss_balanced:.6f}\")\n",
    "print(f\"  Bit Accuracy: {accuracy_balanced*100:.2f}%\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get test batch for visualization\n",
    "test_inputs, test_targets = next(iter(test_loader))\n",
    "\n",
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    test_preds_ctrnn = ctrnn(test_inputs.to(device)).cpu().numpy()\n",
    "    test_preds_balanced = balanced_rnn(test_inputs.to(device)).cpu().numpy()\n",
    "\n",
    "test_inputs_np = test_inputs.numpy()\n",
    "test_targets_np = test_targets.numpy()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot CT-RNN predictions\n",
    "fig = plot_flipflop_trial(\n",
    "    test_inputs_np,\n",
    "    test_targets_np,\n",
    "    test_preds_ctrnn,\n",
    "    trial_idx=0,\n",
    "    figsize=(14, 8)\n",
    ")\n",
    "fig.suptitle('CT-RNN Predictions on Test Trial', fontsize=14, fontweight='bold', y=0.998)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot Balanced RNN predictions\n",
    "fig = plot_flipflop_trial(\n",
    "    test_inputs_np,\n",
    "    test_targets_np,\n",
    "    test_preds_balanced,\n",
    "    trial_idx=0,\n",
    "    figsize=(14, 8)\n",
    ")\n",
    "fig.suptitle('Balanced Rate Network Predictions on Test Trial', fontsize=14, fontweight='bold', y=0.998)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. State-Space Visualization with PCA\n",
    "\n",
    "We'll visualize the hidden state dynamics using PCA to see how the networks represent the 8 possible flip-flop states (2Â³ = 8 combinations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def extract_hidden_states(model, dataloader, device, is_balanced=False):\n",
    "    \"\"\"Extract hidden states from model.\"\"\"\n",
    "    hidden_states = []\n",
    "    targets_list = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            \n",
    "            if is_balanced:\n",
    "                # For balanced network, get hidden states from forward pass\n",
    "                batch_size, seq_len, _ = inputs.shape\n",
    "                h = torch.zeros(batch_size, model.n_excitatory + model.n_inhibitory, device=device)\n",
    "                \n",
    "                for t in range(seq_len):\n",
    "                    h = model.cell(inputs[:, t, :], h)\n",
    "                    hidden_states.append(h.cpu().numpy())\n",
    "                    targets_list.append(targets[:, t, :].numpy())\n",
    "            else:\n",
    "                # For CT-RNN, need to extract hidden states during forward pass\n",
    "                batch_size, seq_len, _ = inputs.shape\n",
    "                h = torch.zeros(batch_size, model.hidden_size, device=device)\n",
    "                \n",
    "                for t in range(seq_len):\n",
    "                    # Integrate one step\n",
    "                    from src.models.ctrnn import CTRNNODEFunc\n",
    "                    ode_func = CTRNNODEFunc(model.cell, inputs[:, t, :])\n",
    "                    t_span = torch.tensor([0.0, 1.0], device=device)\n",
    "                    from torchdiffeq import odeint\n",
    "                    h_traj = odeint(ode_func, h, t_span, method='euler')\n",
    "                    h = h_traj[-1]\n",
    "                    hidden_states.append(h.cpu().numpy())\n",
    "                    targets_list.append(targets[:, t, :].numpy())\n",
    "    \n",
    "    hidden_states = np.vstack(hidden_states)\n",
    "    targets_array = np.vstack(targets_list)\n",
    "    \n",
    "    return hidden_states, targets_array\n",
    "\n",
    "# Extract hidden states\n",
    "print(\"Extracting hidden states from CT-RNN...\")\n",
    "hidden_ctrnn, targets_for_pca = extract_hidden_states(ctrnn, test_loader, device, is_balanced=False)\n",
    "\n",
    "print(\"Extracting hidden states from Balanced RNN...\")\n",
    "hidden_balanced, _ = extract_hidden_states(balanced_rnn, test_loader, device, is_balanced=True)\n",
    "\n",
    "print(f\"\\nExtracted hidden states:\")\n",
    "print(f\"  CT-RNN: {hidden_ctrnn.shape}\")\n",
    "print(f\"  Balanced RNN: {hidden_balanced.shape}\")\n",
    "print(f\"  Targets: {targets_for_pca.shape}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Perform PCA\n",
    "pca_ctrnn = PCA(n_components=3)\n",
    "pca_balanced = PCA(n_components=3)\n",
    "\n",
    "hidden_ctrnn_pca = pca_ctrnn.fit_transform(hidden_ctrnn)\n",
    "hidden_balanced_pca = pca_balanced.fit_transform(hidden_balanced)\n",
    "\n",
    "print(f\"PCA explained variance:\")\n",
    "print(f\"  CT-RNN: {pca_ctrnn.explained_variance_ratio_[:3]}\")\n",
    "print(f\"  Sum: {pca_ctrnn.explained_variance_ratio_[:3].sum():.3f}\")\n",
    "print(f\"\\n  Balanced RNN: {pca_balanced.explained_variance_ratio_[:3]}\")\n",
    "print(f\"  Sum: {pca_balanced.explained_variance_ratio_[:3].sum():.3f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create state labels (convert binary targets to integer labels)\n",
    "state_labels = (targets_for_pca[:, 0] * 4 + targets_for_pca[:, 1] * 2 + targets_for_pca[:, 2]).astype(int)\n",
    "\n",
    "# Plot PCA\n",
    "fig = plt.figure(figsize=(16, 7))\n",
    "\n",
    "# CT-RNN\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "scatter1 = ax1.scatter(\n",
    "    hidden_ctrnn_pca[:5000, 0],\n",
    "    hidden_ctrnn_pca[:5000, 1],\n",
    "    hidden_ctrnn_pca[:5000, 2],\n",
    "    c=state_labels[:5000],\n",
    "    cmap='tab10',\n",
    "    s=5,\n",
    "    alpha=0.6\n",
    ")\n",
    "ax1.set_xlabel('PC1', fontsize=11)\n",
    "ax1.set_ylabel('PC2', fontsize=11)\n",
    "ax1.set_zlabel('PC3', fontsize=11)\n",
    "ax1.set_title('CT-RNN State Space (PCA)', fontsize=13, fontweight='bold')\n",
    "cbar1 = plt.colorbar(scatter1, ax=ax1, pad=0.1, shrink=0.6)\n",
    "cbar1.set_label('Flip-Flop State', fontsize=10)\n",
    "\n",
    "# Balanced RNN\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "scatter2 = ax2.scatter(\n",
    "    hidden_balanced_pca[:5000, 0],\n",
    "    hidden_balanced_pca[:5000, 1],\n",
    "    hidden_balanced_pca[:5000, 2],\n",
    "    c=state_labels[:5000],\n",
    "    cmap='tab10',\n",
    "    s=5,\n",
    "    alpha=0.6\n",
    ")\n",
    "ax2.set_xlabel('PC1', fontsize=11)\n",
    "ax2.set_ylabel('PC2', fontsize=11)\n",
    "ax2.set_zlabel('PC3', fontsize=11)\n",
    "ax2.set_title('Balanced RNN State Space (PCA)', fontsize=13, fontweight='bold')\n",
    "cbar2 = plt.colorbar(scatter2, ax=ax2, pad=0.1, shrink=0.6)\n",
    "cbar2.set_label('Flip-Flop State', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Œ Each color represents one of the 8 possible flip-flop states (000 to 111).\")\n",
    "print(\"   Notice how the network clusters states in the hidden space!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Fixed Point Analysis\n",
    "\n",
    "The flip-flop task should have **8 stable fixed points** (one for each state: 000, 001, 010, ..., 111)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from src.analysis import find_fixed_points, analyze_fixed_point_stability, create_dynamics_fn_from_ctrnn\n",
    "\n",
    "# CT-RNN fixed points\n",
    "print(\"Finding fixed points in CT-RNN...\\n\")\n",
    "dynamics_fn_ctrnn = create_dynamics_fn_from_ctrnn(ctrnn, x=torch.zeros(1, 3, device=device))\n",
    "\n",
    "fixed_points_ctrnn, residuals_ctrnn = find_fixed_points(\n",
    "    dynamics_fn_ctrnn,\n",
    "    hidden_size=64,\n",
    "    n_initial=200,\n",
    "    device=device,\n",
    "    lr=0.01,\n",
    "    max_iters=5000,\n",
    "    tol=1e-5\n",
    ")\n",
    "\n",
    "print(f\"\\nFound {len(fixed_points_ctrnn)} fixed points for CT-RNN\")\n",
    "print(f\"Residual norms: {residuals_ctrnn}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze stability\n",
    "print(\"\\nAnalyzing fixed point stability...\\n\")\n",
    "\n",
    "stable_fps = []\n",
    "for i, fp in enumerate(fixed_points_ctrnn):\n",
    "    # Compute Jacobian\n",
    "    fp_tensor = torch.tensor(fp, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    \n",
    "    # Get dynamics at this point\n",
    "    dhdt = dynamics_fn_ctrnn(fp_tensor)\n",
    "    \n",
    "    # Compute Jacobian using autograd\n",
    "    jac = torch.autograd.functional.jacobian(dynamics_fn_ctrnn, fp_tensor)\n",
    "    \n",
    "    # Analyze stability\n",
    "    analysis = analyze_fixed_point_stability(jac.detach().cpu().numpy())\n",
    "    \n",
    "    if analysis['stable_continuous']:\n",
    "        stable_fps.append(fp)\n",
    "        \n",
    "    print(f\"FP {i}: {analysis['classification']}, stable={analysis['stable_continuous']}, max eig={analysis['max_eigenvalue_real']:.3f}\")\n",
    "\n",
    "print(f\"\\nâœ“ Found {len(stable_fps)} stable fixed points\")\n",
    "print(f\"   Expected: 8 (one per flip-flop state)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Fixed Points in PCA Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Project fixed points to PCA space\n",
    "if len(fixed_points_ctrnn) > 0:\n",
    "    fps_array = np.array(fixed_points_ctrnn)\n",
    "    fps_pca = pca_ctrnn.transform(fps_array)\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 9))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Plot hidden states\n",
    "    ax.scatter(\n",
    "        hidden_ctrnn_pca[:3000, 0],\n",
    "        hidden_ctrnn_pca[:3000, 1],\n",
    "        hidden_ctrnn_pca[:3000, 2],\n",
    "        c=state_labels[:3000],\n",
    "        cmap='tab10',\n",
    "        s=3,\n",
    "        alpha=0.3,\n",
    "        label='Hidden states'\n",
    "    )\n",
    "    \n",
    "    # Plot fixed points\n",
    "    ax.scatter(\n",
    "        fps_pca[:, 0],\n",
    "        fps_pca[:, 1],\n",
    "        fps_pca[:, 2],\n",
    "        c='red',\n",
    "        s=200,\n",
    "        marker='*',\n",
    "        edgecolors='black',\n",
    "        linewidths=2,\n",
    "        label='Fixed points',\n",
    "        zorder=10\n",
    "    )\n",
    "    \n",
    "    ax.set_xlabel('PC1', fontsize=12)\n",
    "    ax.set_ylabel('PC2', fontsize=12)\n",
    "    ax.set_zlabel('PC3', fontsize=12)\n",
    "    ax.set_title('Fixed Points in State Space', fontsize=14, fontweight='bold')\n",
    "    ax.legend(fontsize=11, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nðŸ“Œ Red stars show fixed points - attractors for each flip-flop state!\")\n",
    "else:\n",
    "    print(\"No fixed points found to visualize.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Summary and Comparison\n",
    "\n",
    "Let's compare the two architectures on the flip-flop task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create comparison table\n",
    "comparison_data = {\n",
    "    'Metric': [\n",
    "        'Parameters',\n",
    "        'Test MSE Loss',\n",
    "        'Bit Accuracy (%)',\n",
    "        'Best Val Loss',\n",
    "        'PCA Variance (3 PCs)',\n",
    "        'Fixed Points Found',\n",
    "        'Time Constant Ï„'\n",
    "    ],\n",
    "    'CT-RNN': [\n",
    "        f\"{n_params:,}\",\n",
    "        f\"{test_loss_ctrnn:.6f}\",\n",
    "        f\"{accuracy_ctrnn*100:.2f}%\",\n",
    "        f\"{min(history_ctrnn['val_loss']):.6f}\",\n",
    "        f\"{pca_ctrnn.explained_variance_ratio_[:3].sum():.3f}\",\n",
    "        f\"{len(fixed_points_ctrnn)} ({len(stable_fps)} stable)\",\n",
    "        \"5.0\"\n",
    "    ],\n",
    "    'Balanced Rate': [\n",
    "        f\"{n_params_balanced:,}\",\n",
    "        f\"{test_loss_balanced:.6f}\",\n",
    "        f\"{accuracy_balanced*100:.2f}%\",\n",
    "        f\"{min(history_balanced['val_loss']):.6f}\",\n",
    "        f\"{pca_balanced.explained_variance_ratio_[:3].sum():.3f}\",\n",
    "        \"N/A\",\n",
    "        \"Ï„_E=5.0, Ï„_I=2.5\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ARCHITECTURE COMPARISON ON FLIP-FLOP TASK\")\n",
    "print(\"=\"*80)\n",
    "print(df_comparison.to_string(index=False))\n",
    "print(\"=\"*80)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "### Working Memory Representation\n",
    "- Both networks successfully learn to maintain flip-flop states over time\n",
    "- The 8 distinct states (000 to 111) are visible as clusters in PCA space\n",
    "- Fixed points correspond to stable memory states\n",
    "\n",
    "### Architecture Trade-offs\n",
    "- **CT-RNN**: Continuous dynamics, smooth state transitions, explicit time constant\n",
    "- **Balanced Rate**: E/I structure, biologically-inspired, separate excitatory/inhibitory populations\n",
    "\n",
    "### Task Characteristics\n",
    "- **Working memory**: Networks must maintain state with sparse inputs\n",
    "- **Discrete states**: 8 stable attractors (vs. continuous Lorenz attractor)\n",
    "- **Longer time constants**: Ï„=5.0 (vs. Ï„=1.0 for Lorenz) for memory retention\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. âœ… Use the framework with a different task (flip-flop vs. Lorenz)\n",
    "2. âœ… Generate task-specific data in `src/data/`\n",
    "3. âœ… Train and compare multiple architectures\n",
    "4. âœ… Visualize state-space representations with PCA\n",
    "5. âœ… Analyze fixed point structure\n",
    "\n",
    "**Try your own tasks!** Follow this pattern:\n",
    "- Create data generation in `src/data/your_task.py`\n",
    "- Use existing models from `src/models/`\n",
    "- Apply analysis tools from `src/analysis/`\n",
    "- Visualize with `src/utils/` plotting functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
